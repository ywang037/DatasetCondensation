{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "from unittest import TestLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import data_preparation, gen_data_partition_iid, get_network, get_eval_pool,  get_time, make_client_dataset_from_partition, ParamDiffAug \n",
    "from utils import get_loops, get_dataset, gen_data_partition_dirichlet, evaluate_synset, get_daparam, match_loss, TensorDataset, epoch, DiffAugment\n",
    "\n",
    "import random\n",
    "from client import ClientDC\n",
    "from server import ServerDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argparser():\n",
    "    parser = argparse.ArgumentParser(description='Federated DC using gradient matching')\n",
    "\n",
    "    # default args - data set and model\n",
    "    parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "    parser.add_argument('--data_path', type=str, default='data', help='dataset path')\n",
    "    parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "\n",
    "    # default args - condensation\n",
    "    parser.add_argument('--method', type=str, default='DC', help='DC/DSA')\n",
    "    parser.add_argument('--dsa_strategy', type=str, default='None', help='differentiable Siamese augmentation strategy')  \n",
    "    parser.add_argument('--init', type=str, default='noise', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "    parser.add_argument('--ipc', type=int, default=1, help='image(s) per class')\n",
    "    parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric for gradient matching')\n",
    "    parser.add_argument('--lr_img', type=float, default=0.1, help='learning rate for updating synthetic images')\n",
    "    parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "\n",
    "    # default args - evluation\n",
    "    parser.add_argument('--eval_mode', type=str, default='S', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "    parser.add_argument('--num_eval', type=int, default=20, help='the number randomly initialized models for evaluating the syn data')\n",
    "    parser.add_argument('--epoch_eval_train', type=int, default=300, help='epochs to train a model with synthetic data for evaluating the syn data')\n",
    "\n",
    "    # default args - experiments\n",
    "    parser.add_argument('--num_exp', type=int, default=5, help='the number of experiment runs')  \n",
    "    parser.add_argument('--Iteration', type=int, default=1000, help='the number of model intializations to be used, i.e., big K in the paper gradient matching')\n",
    "\n",
    "    # args - fed/overall\n",
    "    parser.add_argument('--seed', type=int, default=3, help='set a seed for reproducability, set to 0 to activate randomness')\n",
    "    parser.add_argument('--num_clients', type=int, default=5, help='number of clients')\n",
    "    parser.add_argument('--client_alpha', type=float, default=100.0, help='dirichlet alpha that controls the non-iid degree')\n",
    "    \n",
    "    # args - fed/server\n",
    "    parser.add_argument('--stand_alone', action='store_true', default=False, help='trigger non-federated local training mode')\n",
    "    parser.add_argument('--server_mode', type=str, default='train', help='operation model of server train or agg')\n",
    "    parser.add_argument('--server_lr', type=float, default=0.01, help='learning rate for updating global model by the server')\n",
    "    parser.add_argument('--server_batch_train', type=int, default=128, help='batch size for training networks')\n",
    "    parser.add_argument('--server_epoch_train', type=int, default=10, help='epochs to train the global model with synthetic data')\n",
    "    \n",
    "    # args - fed/clients\n",
    "    parser.add_argument('--rounds', type=int, default=10, help='epochs to train the global model with synthetic data')\n",
    "    parser.add_argument('--client_epoch_train', type=int, default=10, help='epochs to train the local model with synthetic data')\n",
    "    parser.add_argument('--client_batch_train_data', type=int, default=256, help='batch size for real data')\n",
    "    parser.add_argument('--client_batch_train_model', type=int, default=128, help='batch size for training networks')\n",
    "\n",
    "    # args - results\n",
    "    parser.add_argument('--save_results', action='store_true', default=False, help='use this to save trained synthetic data and images')\n",
    "    parser.add_argument('--save_root', type=str, default='result', help='path to save results')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.stand_alone:\n",
    "        save_tag = args.dataset + '_local' + time.strftime('_%y-%m-%d-%H-%M-%S') \n",
    "    elif args.server_mode == 'agg': # use model aggregation mode\n",
    "        save_tag = args.dataset + '_fed_agg' + time.strftime('_%y-%m-%d-%H-%M-%S') \n",
    "    elif args.server_mode == 'train': # use model training mode\n",
    "        save_tag = args.dataset + '_fed_train' + time.strftime('_%y-%m-%d-%H-%M-%S') \n",
    "    args.save_path = os.path.join(args.save_root, save_tag) \n",
    "\n",
    "    # the following are original arguments better to be kept unchanged\n",
    "    # args.outer_loop, args.inner_loop = 10, 10\n",
    "    # args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
    "    args.dsa_param = ParamDiffAug()\n",
    "    args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "args=argparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(method='DC', dataset='MNIST', model='ConvNet', ipc=2, eval_mode='S', num_exp=1, num_eval=1, epoch_eval_train=1, Iteration=10, lr_img=0.1, lr_net=0.01, batch_real=256, batch_train=256, init='noise', dsa_strategy='None', data_path='data', save_root='result', dis_metric='ours', num_clients=5, seed=3, client_alpha=100.0, stand_alone=False, save_results=True, outer_loop=10, inner_loop=10, dsa_param=<utils.ParamDiffAug object at 0x0000020D6693A280>, dsa=False, save_path='result\\\\CIFAR10_fed_22-08-19-11-51-57_notebook', device='cuda')\n"
     ]
    }
   ],
   "source": [
    "args.dataset = 'MNIST'\n",
    "args.save_results = True\n",
    "args.ipc = 2\n",
    "args.num_exp = 1\n",
    "args.num_eval = 1\n",
    "args.epoch_eval_train = 1\n",
    "args.Iteration=10\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_it_pool:  [10]\n"
     ]
    }
   ],
   "source": [
    "''' set seeds '''\n",
    "if args.seed:\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "rng = np.random.default_rng(args.seed)    \n",
    "\n",
    "''' some global setup '''\n",
    "# if not os.path.exists(args.data_path):\n",
    "#     os.mkdir(args.data_path)\n",
    "if not os.path.exists(args.save_path):\n",
    "    os.mkdir(args.save_path)\n",
    "\n",
    "# The list of iterations when we evaluate models and record results.\n",
    "# the defualt setting is to evaluate every 500 iterations, i.e., k=n*500\n",
    "# eval_it_pool = np.arange(0, args.Iteration+1, 500).tolist() if args.eval_mode == 'S' or args.eval_mode == 'SS' else [args.Iteration] \n",
    "eval_it_pool = [args.Iteration] # only evaluate at last iteration\n",
    "print('eval_it_pool: ', eval_it_pool)\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "data_set, data_info, testloader_server = data_preparation(args.dataset)\n",
    "\n",
    "accs_all_clients_all_exps = [dict() for i in range(args.num_clients)]\n",
    "for i in range(args.num_clients):\n",
    "    for key in model_eval_pool:\n",
    "        accs_all_clients_all_exps[i][key]=[]\n",
    "data_save_all_clients = [[] for i in range(args.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Exp 0 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'method': 'DC', 'dataset': 'MNIST', 'model': 'ConvNet', 'ipc': 2, 'eval_mode': 'S', 'num_exp': 1, 'num_eval': 1, 'epoch_eval_train': 1, 'Iteration': 10, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_root': 'result', 'dis_metric': 'ours', 'num_clients': 5, 'seed': 3, 'client_alpha': 100.0, 'stand_alone': False, 'save_results': True, 'outer_loop': 10, 'inner_loop': 10, 'dsa_param': <utils.ParamDiffAug object at 0x0000020D6693A280>, 'dsa': False, 'save_path': 'result\\\\CIFAR10_fed_22-08-19-11-51-57_notebook', 'device': 'cuda'}\n",
      "Evaluation model pool:  ['ConvNet']\n",
      "Client 0 has 12000 training samples 2000 testing samples\n",
      "Client 1 has 12000 training samples 2000 testing samples\n",
      "Client 2 has 12000 training samples 2000 testing samples\n",
      "Client 3 has 12000 training samples 2000 testing samples\n",
      "Client 4 has 12000 training samples 2000 testing samples\n",
      "FL server created.\n",
      "class c = 0: 1163 real images\n",
      "class c = 1: 1346 real images\n",
      "class c = 2: 1175 real images\n",
      "class c = 3: 1237 real images\n",
      "class c = 4: 1168 real images\n",
      "class c = 5: 1122 real images\n",
      "class c = 6: 1178 real images\n",
      "class c = 7: 1274 real images\n",
      "class c = 8: 1157 real images\n",
      "class c = 9: 1180 real images\n",
      "real images channel 0, mean = 0.0005, std = 1.0009\n",
      "initialize synthetic data from random noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YWANG\\atr-data-distillation\\DatasetCondensation\\client.py:83: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  self.label_syn = torch.tensor([np.ones(self.ipc)*i for i in range(self.num_classes)], dtype=torch.long, requires_grad=False, device=self.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class c = 0: 1163 real images\n",
      "class c = 1: 1346 real images\n",
      "class c = 2: 1175 real images\n",
      "class c = 3: 1237 real images\n",
      "class c = 4: 1168 real images\n",
      "class c = 5: 1122 real images\n",
      "class c = 6: 1178 real images\n",
      "class c = 7: 1274 real images\n",
      "class c = 8: 1157 real images\n",
      "class c = 9: 1180 real images\n",
      "real images channel 0, mean = 0.0005, std = 1.0009\n",
      "initialize synthetic data from random noise\n",
      "class c = 0: 1163 real images\n",
      "class c = 1: 1346 real images\n",
      "class c = 2: 1175 real images\n",
      "class c = 3: 1237 real images\n",
      "class c = 4: 1168 real images\n",
      "class c = 5: 1122 real images\n",
      "class c = 6: 1178 real images\n",
      "class c = 7: 1274 real images\n",
      "class c = 8: 1157 real images\n",
      "class c = 9: 1180 real images\n",
      "real images channel 0, mean = 0.0005, std = 1.0009\n",
      "initialize synthetic data from random noise\n",
      "class c = 0: 1163 real images\n",
      "class c = 1: 1346 real images\n",
      "class c = 2: 1175 real images\n",
      "class c = 3: 1237 real images\n",
      "class c = 4: 1168 real images\n",
      "class c = 5: 1122 real images\n",
      "class c = 6: 1178 real images\n",
      "class c = 7: 1274 real images\n",
      "class c = 8: 1157 real images\n",
      "class c = 9: 1180 real images\n",
      "real images channel 0, mean = 0.0005, std = 1.0009\n",
      "initialize synthetic data from random noise\n",
      "class c = 0: 1163 real images\n",
      "class c = 1: 1346 real images\n",
      "class c = 2: 1175 real images\n",
      "class c = 3: 1237 real images\n",
      "class c = 4: 1168 real images\n",
      "class c = 5: 1122 real images\n",
      "class c = 6: 1178 real images\n",
      "class c = 7: 1274 real images\n",
      "class c = 8: 1157 real images\n",
      "class c = 9: 1180 real images\n",
      "real images channel 0, mean = 0.0005, std = 1.0009\n",
      "initialize synthetic data from random noise\n",
      "[2022-08-19 11:52:28] training begins\n",
      "[2022-08-19 11:53:25] iter = 0000, loss = 218.1439\n",
      "[2022-08-19 11:53:25] iter = 0000, loss = 224.0778\n",
      "[2022-08-19 11:53:25] iter = 0000, loss = 217.3681\n",
      "[2022-08-19 11:53:25] iter = 0000, loss = 224.5482\n",
      "[2022-08-19 11:53:25] iter = 0000, loss = 221.6231\n",
      "-------------------------\n",
      "Evaluation\n",
      "model_train = ConvNet, model_eval = ConvNet, iteration = 10\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "[2022-08-19 12:02:03] Evaluate_00: epoch = 0300 train time = 6 s train loss = 0.070086 train acc = 1.0000, test acc = 0.8965\n",
      "Evaluate 1 random ConvNet, mean = 0.8965 std = 0.0000\n",
      "-------------------------\n",
      "[2022-08-19 12:02:03] iter = 0010, loss = 77.3209\n",
      "-------------------------\n",
      "Evaluation\n",
      "model_train = ConvNet, model_eval = ConvNet, iteration = 10\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "[2022-08-19 12:02:10] Evaluate_00: epoch = 0300 train time = 5 s train loss = 0.022301 train acc = 1.0000, test acc = 0.8320\n",
      "Evaluate 1 random ConvNet, mean = 0.8320 std = 0.0000\n",
      "-------------------------\n",
      "[2022-08-19 12:02:10] iter = 0010, loss = 76.9790\n",
      "-------------------------\n",
      "Evaluation\n",
      "model_train = ConvNet, model_eval = ConvNet, iteration = 10\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "[2022-08-19 12:02:16] Evaluate_00: epoch = 0300 train time = 5 s train loss = 0.009119 train acc = 1.0000, test acc = 0.8915\n",
      "Evaluate 1 random ConvNet, mean = 0.8915 std = 0.0000\n",
      "-------------------------\n",
      "[2022-08-19 12:02:16] iter = 0010, loss = 74.3258\n",
      "-------------------------\n",
      "Evaluation\n",
      "model_train = ConvNet, model_eval = ConvNet, iteration = 10\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "[2022-08-19 12:02:22] Evaluate_00: epoch = 0300 train time = 5 s train loss = 0.017872 train acc = 1.0000, test acc = 0.8720\n",
      "Evaluate 1 random ConvNet, mean = 0.8720 std = 0.0000\n",
      "-------------------------\n",
      "[2022-08-19 12:02:22] iter = 0010, loss = 75.4030\n",
      "-------------------------\n",
      "Evaluation\n",
      "model_train = ConvNet, model_eval = ConvNet, iteration = 10\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "[2022-08-19 12:02:28] Evaluate_00: epoch = 0300 train time = 5 s train loss = 0.008736 train acc = 1.0000, test acc = 0.8785\n",
      "Evaluate 1 random ConvNet, mean = 0.8785 std = 0.0000\n",
      "-------------------------\n",
      "[2022-08-19 12:02:28] iter = 0010, loss = 75.9705\n"
     ]
    }
   ],
   "source": [
    "# looping over multiple experiment trials\n",
    "for exp in range(args.num_exp):\n",
    "    print('\\n================== Exp %d ==================\\n '%exp)\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "    print('Evaluation model pool: ', model_eval_pool)\n",
    "\n",
    "    # split data set for each client'''       \n",
    "    # generate training data partitioning using IID method\n",
    "    client_train_data_idcs, client_train_class_dict = gen_data_partition_iid(\n",
    "        data=data_set['train_data'], \n",
    "        num_classes=data_info['num_classes'], \n",
    "        labels=data_set['train_labels'], \n",
    "        data_mapp=data_set['mapp'],\n",
    "        num_clients=args.num_clients, \n",
    "        generator=rng, \n",
    "        verbose_hist=False)\n",
    "\n",
    "    client_test_data_idcs, client_test_class_dict = gen_data_partition_iid(\n",
    "        data=data_set['test_data'], \n",
    "        num_classes=data_info['num_classes'], \n",
    "        labels=data_set['test_labels'], \n",
    "        data_mapp=data_set['mapp'],\n",
    "        num_clients=args.num_clients, \n",
    "        generator=rng, \n",
    "        verbose_hist=False)\n",
    "\n",
    "    # make client data using the generated partition\n",
    "    client_data_train = make_client_dataset_from_partition(data_set['train_data'], args.num_clients, client_train_data_idcs)\n",
    "    client_data_test = make_client_dataset_from_partition(data_set['test_data'], args.num_clients, client_test_data_idcs)\n",
    "\n",
    "    # set the architecture for the network to be trained\n",
    "    net_train = get_network(args.model, data_info['channel'], data_info['num_classes'], data_info['img_size']).to(args.device)\n",
    "\n",
    "    # create clients and server\n",
    "    clients = [ClientDC(id, args, net_train, data_info, client_data_train[i], client_data_test[i], eval_it_pool, model_eval_pool) for id in range(args.num_clients)]\n",
    "    for client in clients:\n",
    "        print('Client {} has {} training samples {} testing samples'.format(client.id, client.num_local_data_train, client.num_local_data_test))\n",
    "    server = ServerDC(args, net_train, clients, data_info)\n",
    "    print('FL server created.')\n",
    "\n",
    "    # organize the real dataset and initialize the synthetic data\n",
    "    for client in clients:\n",
    "        client.organize_local_real_data()\n",
    "        for ch in range(client.channel):\n",
    "            print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(client.images_all[:, ch]), torch.std(client.images_all[:, ch])))\n",
    "        client.syn_data_init()\n",
    "        client.data_trainer_setup() # only to be called after syn_data_init()\n",
    "\n",
    "    # training starts from here\n",
    "    print('%s training begins'%get_time())\n",
    "    \n",
    "    # NOTE this loop is over the different model initializations, i.e., the loop indixed by K in the paper, Algorithm 1 line 4\n",
    "    for it in range(args.Iteration+1): \n",
    "        # get a new random initialization of the network\n",
    "        server.global_model = get_network(args.model, data_info['channel'], data_info['num_classes'], data_info['img_size']).to(args.device) \n",
    "        server.global_model_state = server.global_model.state_dict()\n",
    "        \n",
    "        for client in clients:\n",
    "            # # get a new random initialization of the network\n",
    "            # client.model_train = get_network(args.model, client.channel, client.num_classes, client.im_size).to(args.device) \n",
    "\n",
    "            # fetch newly intialized server model weights\n",
    "            client.sync_with_server(server, method='state')\n",
    "\n",
    "            # set the optimizer for learning synthetic data\n",
    "            optimizer_net = client.net_trainer_setup(client.model_train)\n",
    "\n",
    "\n",
    "        # NOTE this loop is indixed by T in the paper, Algorithm 1 line 4\n",
    "        # this loop resembles the communication round in FL\n",
    "        for ol in range(args.rounds): \n",
    "\n",
    "            # clients perform local update of data and network '''\n",
    "            for client in clients:\n",
    "                if not args.stand_alone and ol:\n",
    "                    client.sync_with_server(server, method='state') # fetch server model weights\n",
    "\n",
    "                # freeze the running mu and sigma for BatchNorm layers '''\n",
    "                # Synthetic data batch, e.g. only 1 image/batch, is too small to obtain stable mu and sigma.\n",
    "                # So, we calculate and freeze mu and sigma for BatchNorm layer with real data batch ahead.\n",
    "                # This would make the training with BatchNorm layers easier.\n",
    "                BN_flag = False\n",
    "                BNSizePC = 16  # for batch normalization\n",
    "                for module in client.model_train.modules():\n",
    "                    if 'BatchNorm' in module._get_name(): #BatchNorm\n",
    "                        BN_flag = True\n",
    "                if BN_flag:\n",
    "                    img_real = torch.cat([client.get_images(c, BNSizePC) for c in range(client.num_classes)], dim=0)\n",
    "                    client.model_train.train() # for updating the mu, sigma of BatchNorm\n",
    "                    output_real = client.model_train(img_real) # get running mu, sigma\n",
    "                    for module in client.model_train.modules():\n",
    "                        if 'BatchNorm' in module._get_name():  #BatchNorm\n",
    "                            module.eval() # fix mu and sigma of every BatchNorm layer\n",
    "\n",
    "                # local update of synthetic data '''\n",
    "                # one step of SGD, can be repeated for multiple steps\n",
    "                # update only once but over T iterations equivalent to T steps of SGD for learning the data\n",
    "                client.syn_data_update(client.model_train) \n",
    "\n",
    "                # local update of network (using synthetic data) '''\n",
    "                client.network_update(client.model_train, optimizer_net) \n",
    "                client.local_model_state = copy.deepcopy(client.model_train.state_dict()) # copy the updated local model weights to another iterables to avoid any unaware modification   \n",
    "\n",
    "            # Server perform model aggregation upon local network updates\n",
    "            if not args.stand_alone:\n",
    "                server.net_weights_aggregation(clients)\n",
    "\n",
    "        # Evaluate synthetic data trained in last iteration\n",
    "        for client in clients:\n",
    "            client.syn_data_eval(exp, it, accs_all_clients_all_exps)\n",
    "            client.loss_avg /= (client.num_classes*args.rounds) # Summary for client data condensation for this exp trial\n",
    "\n",
    "            if not os.path.exists(client.save_path):\n",
    "                os.mkdir(client.save_path)\n",
    "            \n",
    "            if it%10 == 0:\n",
    "                print('%s iter = %04d, loss = %.4f' % (get_time(), it, client.loss_avg))\n",
    "            if it == args.Iteration and args.save_results: # only record the final results\n",
    "                data_save_all_clients[client.id].append([copy.deepcopy(client.image_syn.detach().cpu()), copy.deepcopy(client.label_syn.detach().cpu())])\n",
    "                torch.save({'data': data_save_all_clients[client.id], 'accs_all_exps': accs_all_clients_all_exps[client.id], }, os.path.join(client.save_path, 'res_%s_%s_%s_%dipc.pt'%(client.args.method, client.args.dataset, client.args.model, client.args.ipc)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Final Results ====================\n",
      "\n",
      "Client 0 run 1 experiments, train on ConvNet, evaluate 1 random ConvNet, mean  = 89.65%  std = 0.00%\n",
      "Client 1 run 1 experiments, train on ConvNet, evaluate 1 random ConvNet, mean  = 83.20%  std = 0.00%\n",
      "Client 2 run 1 experiments, train on ConvNet, evaluate 1 random ConvNet, mean  = 89.15%  std = 0.00%\n",
      "Client 3 run 1 experiments, train on ConvNet, evaluate 1 random ConvNet, mean  = 87.20%  std = 0.00%\n",
      "Client 4 run 1 experiments, train on ConvNet, evaluate 1 random ConvNet, mean  = 87.85%  std = 0.00%\n",
      "\n",
      "-------------------------\n",
      "Average performance after 1 experiments, evaluted on  5 random ConvNet, mean = 87.41%, std = 0.00%\n"
     ]
    }
   ],
   "source": [
    "print('\\n==================== Final Results ====================\\n')\n",
    "for key in model_eval_pool:\n",
    "    acc_overall = []\n",
    "    for i in range(args.num_clients):\n",
    "        accs = accs_all_clients_all_exps[i][key]\n",
    "        print('Client %d run %d experiments, train on %s, evaluate %d random %s, mean  = %.2f%%  std = %.2f%%'%(i, args.num_exp, args.model, len(accs), key, np.mean(accs)*100, np.std(accs)*100))\n",
    "        acc_overall += accs\n",
    "    print('\\n-------------------------\\nAverage performance after {:d} experiments, evaluted on {:2d} random {}, mean = {:.2f}%, std = {:.2f}%'.format(args.num_exp, len(acc_overall), args.model, np.mean(acc_overall)*100, np.std(accs)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_client = clients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_client.label_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_client = clients[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_data.append(the_client.image_syn)\n",
    "all_data.append(another_client.image_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YWANG\\atr-data-distillation\\DatasetCondensation\\debug_FedDC.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/YWANG/atr-data-distillation/DatasetCondensation/debug_FedDC.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mtensor(all_data)\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_client.image_syn[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = torch.cat((the_client.image_syn, another_client.image_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 28, 28])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = torch.cat((the_client.label_syn,another_client.label_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 0, 0, 1, 1,\n",
       "        2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_syn_train, label_syn_train = copy.deepcopy(all_data.detach()), copy.deepcopy(all_label.detach()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_syn_train = TensorDataset(image_syn_train, label_syn_train)\n",
    "net_trainloader = torch.utils.data.DataLoader(dataset_syn_train, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.TensorDataset at 0x20d174d1460>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_syn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_syn_train.images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = clients[0].label_syn\n",
    "for id in range(1,args.num_clients):\n",
    "    all_label = torch.cat((all_label, clients[id].label_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = copy.deepcopy(clients[0].image_syn)\n",
    "for id in range(1,args.num_clients):\n",
    "    all_data = torch.cat((all_data, copy.deepcopy(clients[id].image_syn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_syn_train, label_syn_train = copy.deepcopy(all_data.detach()), copy.deepcopy(all_label.detach()) \n",
    "dataset_syn_train = TensorDataset(image_syn_train, label_syn_train)\n",
    "net_trainloader = torch.utils.data.DataLoader(dataset_syn_train, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_syn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_data, all_label, image_syn_train, label_syn_train, dataset_syn_train, net_trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('atr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fb7ec950fe6b28ba376f5ac2aa4547481897296ca80154442a226616f8f80b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
